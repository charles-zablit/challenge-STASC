{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import logging\n",
    "import pathlib\n",
    "from typing import Tuple, List\n",
    "\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_file = pathlib.Path(\"data/X_train_G3tdtEn.csv\")\n",
    "y_train_file = pathlib.Path(\"data/Y_train_2_XPXJDyy.csv\")\n",
    "X_test_file = pathlib.Path(\"data/X_test_8skS2ey.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Word2Vec transformer class\n",
    "class W2V(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_words=None, **kwargs):\n",
    "        self.num_words = num_words\n",
    "        self.tokenizer = Tokenizer(num_words=num_words, **kwargs)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.Word2 = api.load(\"word2vec-google-news-300\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        x = np.array(X.values)\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x[i])):\n",
    "                tokens = x[i][j].split()\n",
    "                embeddings = [\n",
    "                    self.Word2[token]\n",
    "                    for token in tokens\n",
    "                    if token in self.Word2.key_to_index\n",
    "                ]\n",
    "                if len(embeddings) > 0:\n",
    "                    mean = np.mean(embeddings)\n",
    "                else:\n",
    "                    mean = 0\n",
    "                x[i][j] = mean\n",
    "        return x\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"num_words\": self.num_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_df(path: pathlib.Path) -> pd.DataFrame:\n",
    "    mixed_columns = (\n",
    "        [\"item\" + str(i) for i in range(1, 25)]\n",
    "        + [\"make\" + str(i) for i in range(1, 25)]\n",
    "        + [\"model\" + str(i) for i in range(1, 25)]\n",
    "        + [\"goods_code\" + str(i) for i in range(1, 25)]\n",
    "    )\n",
    "    mixed_columns_dtype = {col: str for col in mixed_columns}\n",
    "    return pd.read_csv(path, dtype=mixed_columns_dtype)\n",
    "\n",
    "\n",
    "def load_test_df(path: pathlib.Path) -> pd.Series:\n",
    "    return pd.read_csv(path)[\"fraud_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_input(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "    cols_base = [\"goods_code\"]\n",
    "    columns_to_drop = [\"ID\"] + [col + str(i) for col in cols_base for i in range(1, 25)]\n",
    "\n",
    "    df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    # Identify the columns to apply RNN tokenization\n",
    "    rnn_columns = [\"make\", \"item\", \"model\"]  # Add more columns as needed\n",
    "    rnn_columns = [col + str(i) for col in rnn_columns for i in range(1, 25)]\n",
    "\n",
    "    # Identify the categorical and numerical columns\n",
    "    categorical_columns = rnn_columns\n",
    "    numerical_columns = [col for col in df.columns if col not in set(categorical_columns)]\n",
    "\n",
    "    # Clean data\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].fillna(\"\")\n",
    "    for col in numerical_columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    return df, categorical_columns, numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = load_train_df(X_train_file)\n",
    "y_train_df = load_test_df(y_train_file)\n",
    "\n",
    "X_train_df, categorical_columns, numerical_columns = df_to_input(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformers\n",
    "cat_pipeline = make_pipeline(W2V())\n",
    "num_pipeline = make_pipeline(StandardScaler())\n",
    "\n",
    "\n",
    "# Create the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat_pipeline\", cat_pipeline, categorical_columns),\n",
    "        (\"num_pipeline\", num_pipeline, numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0, verbose=True)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", rfc)], verbose=True)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_df, y_train_df, test_size=0.2, random_state=0, stratify=y_train_df\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [400, 500, 700],\n",
    "    # \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"model__max_depth\": [10, 20, 30],\n",
    "    # \"criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"average_precision\",\n",
    "    cv=sss,\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  44.9s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  45.2s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  45.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  46.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  45.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.3s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  46.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.5s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.0s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.9s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   10.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   14.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  11.9s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  16.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   14.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  14.3s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  14.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   14.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   14.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   19.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   19.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  20.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  52.1s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  46.8s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  51.2s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  48.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.9s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  50.5s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  50.8s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  46.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  50.1s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  43.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  43.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   17.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  17.7s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  17.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   17.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   18.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   18.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  18.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   20.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  23.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   21.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  24.5s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  21.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   21.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   21.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  21.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   22.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  22.4s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   22.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  46.9s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  45.7s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  44.5s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  48.0s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  48.2s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  48.9s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.3s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  44.6s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  45.3s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  44.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.1s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  47.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   17.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   18.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   18.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  18.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  19.3s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  22.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   22.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  22.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  25.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   31.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   30.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  34.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  33.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   31.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  34.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   31.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   31.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  34.8s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  34.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  38.5s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  39.0s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  41.4s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  37.4s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  35.7s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  39.8s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  42.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  31.9s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  32.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   18.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  20.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   18.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   19.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  21.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  21.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   24.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   25.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  27.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   26.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   24.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   24.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  25.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.8s finished\n",
      "INFO:gensim.models.keyedvectors:loading projection weights from /Users/charles/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "INFO:gensim.utils:KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/charles/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-11-13T22:34:20.864543', 'gensim': '4.3.0', 'python': '3.10.13 (main, Sep 11 2023, 08:24:56) [Clang 14.0.6 ]', 'platform': 'macOS-14.0-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  25.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  12.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   12.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;cat_pipeline&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;w2v&#x27;,\n",
       "                                                                                          W2V())]),\n",
       "                                                                         [&#x27;make1&#x27;,\n",
       "                                                                          &#x27;make2&#x27;,\n",
       "                                                                          &#x27;make3&#x27;,\n",
       "                                                                          &#x27;make4&#x27;,\n",
       "                                                                          &#x27;make5&#x27;,\n",
       "                                                                          &#x27;make6&#x27;,\n",
       "                                                                          &#x27;make7&#x27;,\n",
       "                                                                          &#x27;make8&#x27;,\n",
       "                                                                          &#x27;make9&#x27;,\n",
       "                                                                          &#x27;make10&#x27;,\n",
       "                                                                          &#x27;make11&#x27;,\n",
       "                                                                          &#x27;make12&#x27;,\n",
       "                                                                          &#x27;make13&#x27;,\n",
       "                                                                          &#x27;make14&#x27;,\n",
       "                                                                          &#x27;make15&#x27;,\n",
       "                                                                          &#x27;make16...\n",
       "                                                                          &#x27;Nbr_of_prod_purchas1&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas2&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas3&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas4&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas5&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas6&#x27;, ...])])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0,\n",
       "                                                               verbose=True))],\n",
       "                                verbose=True),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__max_depth&#x27;: [10, 20, 30],\n",
       "                         &#x27;model__n_estimators&#x27;: [400, 500, 700]},\n",
       "             scoring=&#x27;average_precision&#x27;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;cat_pipeline&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;w2v&#x27;,\n",
       "                                                                                          W2V())]),\n",
       "                                                                         [&#x27;make1&#x27;,\n",
       "                                                                          &#x27;make2&#x27;,\n",
       "                                                                          &#x27;make3&#x27;,\n",
       "                                                                          &#x27;make4&#x27;,\n",
       "                                                                          &#x27;make5&#x27;,\n",
       "                                                                          &#x27;make6&#x27;,\n",
       "                                                                          &#x27;make7&#x27;,\n",
       "                                                                          &#x27;make8&#x27;,\n",
       "                                                                          &#x27;make9&#x27;,\n",
       "                                                                          &#x27;make10&#x27;,\n",
       "                                                                          &#x27;make11&#x27;,\n",
       "                                                                          &#x27;make12&#x27;,\n",
       "                                                                          &#x27;make13&#x27;,\n",
       "                                                                          &#x27;make14&#x27;,\n",
       "                                                                          &#x27;make15&#x27;,\n",
       "                                                                          &#x27;make16...\n",
       "                                                                          &#x27;Nbr_of_prod_purchas1&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas2&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas3&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas4&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas5&#x27;,\n",
       "                                                                          &#x27;Nbr_of_prod_purchas6&#x27;, ...])])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0,\n",
       "                                                               verbose=True))],\n",
       "                                verbose=True),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__max_depth&#x27;: [10, 20, 30],\n",
       "                         &#x27;model__n_estimators&#x27;: [400, 500, 700]},\n",
       "             scoring=&#x27;average_precision&#x27;, verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;w2v&#x27;,\n",
       "                                                                   W2V())]),\n",
       "                                                  [&#x27;make1&#x27;, &#x27;make2&#x27;, &#x27;make3&#x27;,\n",
       "                                                   &#x27;make4&#x27;, &#x27;make5&#x27;, &#x27;make6&#x27;,\n",
       "                                                   &#x27;make7&#x27;, &#x27;make8&#x27;, &#x27;make9&#x27;,\n",
       "                                                   &#x27;make10&#x27;, &#x27;make11&#x27;, &#x27;make12&#x27;,\n",
       "                                                   &#x27;make13&#x27;, &#x27;make14&#x27;, &#x27;make15&#x27;,\n",
       "                                                   &#x27;make16&#x27;, &#x27;make17&#x27;, &#x27;make18&#x27;,\n",
       "                                                   &#x27;make19&#x27;, &#x27;make20&#x27;, &#x27;make21&#x27;,\n",
       "                                                   &#x27;make22&#x27;, &#x27;make23&#x27;, &#x27;make24&#x27;,\n",
       "                                                   &#x27;item1&#x27;, &#x27;item2&#x27;, &#x27;item3&#x27;,\n",
       "                                                   &#x27;item4&#x27;,...\n",
       "                                                   &#x27;cash_price16&#x27;,\n",
       "                                                   &#x27;cash_price17&#x27;,\n",
       "                                                   &#x27;cash_price18&#x27;,\n",
       "                                                   &#x27;cash_price19&#x27;,\n",
       "                                                   &#x27;cash_price20&#x27;,\n",
       "                                                   &#x27;cash_price21&#x27;,\n",
       "                                                   &#x27;cash_price22&#x27;,\n",
       "                                                   &#x27;cash_price23&#x27;,\n",
       "                                                   &#x27;cash_price24&#x27;,\n",
       "                                                   &#x27;Nbr_of_prod_purchas1&#x27;,\n",
       "                                                   &#x27;Nbr_of_prod_purchas2&#x27;,\n",
       "                                                   &#x27;Nbr_of_prod_purchas3&#x27;,\n",
       "                                                   &#x27;Nbr_of_prod_purchas4&#x27;,\n",
       "                                                   &#x27;Nbr_of_prod_purchas5&#x27;,\n",
       "                                                   &#x27;Nbr_of_prod_purchas6&#x27;, ...])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomForestClassifier(random_state=0, verbose=True))],\n",
       "         verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;w2v&#x27;, W2V())]),\n",
       "                                 [&#x27;make1&#x27;, &#x27;make2&#x27;, &#x27;make3&#x27;, &#x27;make4&#x27;, &#x27;make5&#x27;,\n",
       "                                  &#x27;make6&#x27;, &#x27;make7&#x27;, &#x27;make8&#x27;, &#x27;make9&#x27;, &#x27;make10&#x27;,\n",
       "                                  &#x27;make11&#x27;, &#x27;make12&#x27;, &#x27;make13&#x27;, &#x27;make14&#x27;,\n",
       "                                  &#x27;make15&#x27;, &#x27;make16&#x27;, &#x27;make17&#x27;, &#x27;make18&#x27;,\n",
       "                                  &#x27;make19&#x27;, &#x27;make20&#x27;, &#x27;make21&#x27;, &#x27;make22&#x27;,\n",
       "                                  &#x27;make23&#x27;, &#x27;make24&#x27;, &#x27;item1&#x27;, &#x27;item2&#x27;, &#x27;item3&#x27;,\n",
       "                                  &#x27;item4&#x27;, &#x27;item5&#x27;, &#x27;item6&#x27;, ...]),\n",
       "                                (&#x27;num_pi...\n",
       "                                  &#x27;cash_price10&#x27;, &#x27;cash_price11&#x27;,\n",
       "                                  &#x27;cash_price12&#x27;, &#x27;cash_price13&#x27;,\n",
       "                                  &#x27;cash_price14&#x27;, &#x27;cash_price15&#x27;,\n",
       "                                  &#x27;cash_price16&#x27;, &#x27;cash_price17&#x27;,\n",
       "                                  &#x27;cash_price18&#x27;, &#x27;cash_price19&#x27;,\n",
       "                                  &#x27;cash_price20&#x27;, &#x27;cash_price21&#x27;,\n",
       "                                  &#x27;cash_price22&#x27;, &#x27;cash_price23&#x27;,\n",
       "                                  &#x27;cash_price24&#x27;, &#x27;Nbr_of_prod_purchas1&#x27;,\n",
       "                                  &#x27;Nbr_of_prod_purchas2&#x27;,\n",
       "                                  &#x27;Nbr_of_prod_purchas3&#x27;,\n",
       "                                  &#x27;Nbr_of_prod_purchas4&#x27;,\n",
       "                                  &#x27;Nbr_of_prod_purchas5&#x27;,\n",
       "                                  &#x27;Nbr_of_prod_purchas6&#x27;, ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;make1&#x27;, &#x27;make2&#x27;, &#x27;make3&#x27;, &#x27;make4&#x27;, &#x27;make5&#x27;, &#x27;make6&#x27;, &#x27;make7&#x27;, &#x27;make8&#x27;, &#x27;make9&#x27;, &#x27;make10&#x27;, &#x27;make11&#x27;, &#x27;make12&#x27;, &#x27;make13&#x27;, &#x27;make14&#x27;, &#x27;make15&#x27;, &#x27;make16&#x27;, &#x27;make17&#x27;, &#x27;make18&#x27;, &#x27;make19&#x27;, &#x27;make20&#x27;, &#x27;make21&#x27;, &#x27;make22&#x27;, &#x27;make23&#x27;, &#x27;make24&#x27;, &#x27;item1&#x27;, &#x27;item2&#x27;, &#x27;item3&#x27;, &#x27;item4&#x27;, &#x27;item5&#x27;, &#x27;item6&#x27;, &#x27;item7&#x27;, &#x27;item8&#x27;, &#x27;item9&#x27;, &#x27;item10&#x27;, &#x27;item11&#x27;, &#x27;item12&#x27;, &#x27;item13&#x27;, &#x27;item14&#x27;, &#x27;item15&#x27;, &#x27;item16&#x27;, &#x27;item17&#x27;, &#x27;item18&#x27;, &#x27;item19&#x27;, &#x27;item20&#x27;, &#x27;item21&#x27;, &#x27;item22&#x27;, &#x27;item23&#x27;, &#x27;item24&#x27;, &#x27;model1&#x27;, &#x27;model2&#x27;, &#x27;model3&#x27;, &#x27;model4&#x27;, &#x27;model5&#x27;, &#x27;model6&#x27;, &#x27;model7&#x27;, &#x27;model8&#x27;, &#x27;model9&#x27;, &#x27;model10&#x27;, &#x27;model11&#x27;, &#x27;model12&#x27;, &#x27;model13&#x27;, &#x27;model14&#x27;, &#x27;model15&#x27;, &#x27;model16&#x27;, &#x27;model17&#x27;, &#x27;model18&#x27;, &#x27;model19&#x27;, &#x27;model20&#x27;, &#x27;model21&#x27;, &#x27;model22&#x27;, &#x27;model23&#x27;, &#x27;model24&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">W2V</label><div class=\"sk-toggleable__content\"><pre>W2V()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;cash_price1&#x27;, &#x27;cash_price2&#x27;, &#x27;cash_price3&#x27;, &#x27;cash_price4&#x27;, &#x27;cash_price5&#x27;, &#x27;cash_price6&#x27;, &#x27;cash_price7&#x27;, &#x27;cash_price8&#x27;, &#x27;cash_price9&#x27;, &#x27;cash_price10&#x27;, &#x27;cash_price11&#x27;, &#x27;cash_price12&#x27;, &#x27;cash_price13&#x27;, &#x27;cash_price14&#x27;, &#x27;cash_price15&#x27;, &#x27;cash_price16&#x27;, &#x27;cash_price17&#x27;, &#x27;cash_price18&#x27;, &#x27;cash_price19&#x27;, &#x27;cash_price20&#x27;, &#x27;cash_price21&#x27;, &#x27;cash_price22&#x27;, &#x27;cash_price23&#x27;, &#x27;cash_price24&#x27;, &#x27;Nbr_of_prod_purchas1&#x27;, &#x27;Nbr_of_prod_purchas2&#x27;, &#x27;Nbr_of_prod_purchas3&#x27;, &#x27;Nbr_of_prod_purchas4&#x27;, &#x27;Nbr_of_prod_purchas5&#x27;, &#x27;Nbr_of_prod_purchas6&#x27;, &#x27;Nbr_of_prod_purchas7&#x27;, &#x27;Nbr_of_prod_purchas8&#x27;, &#x27;Nbr_of_prod_purchas9&#x27;, &#x27;Nbr_of_prod_purchas10&#x27;, &#x27;Nbr_of_prod_purchas11&#x27;, &#x27;Nbr_of_prod_purchas12&#x27;, &#x27;Nbr_of_prod_purchas13&#x27;, &#x27;Nbr_of_prod_purchas14&#x27;, &#x27;Nbr_of_prod_purchas15&#x27;, &#x27;Nbr_of_prod_purchas16&#x27;, &#x27;Nbr_of_prod_purchas17&#x27;, &#x27;Nbr_of_prod_purchas18&#x27;, &#x27;Nbr_of_prod_purchas19&#x27;, &#x27;Nbr_of_prod_purchas20&#x27;, &#x27;Nbr_of_prod_purchas21&#x27;, &#x27;Nbr_of_prod_purchas22&#x27;, &#x27;Nbr_of_prod_purchas23&#x27;, &#x27;Nbr_of_prod_purchas24&#x27;, &#x27;Nb_of_items&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0, verbose=True)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        ColumnTransformer(transformers=[('cat_pipeline',\n",
       "                                                                         Pipeline(steps=[('w2v',\n",
       "                                                                                          W2V())]),\n",
       "                                                                         ['make1',\n",
       "                                                                          'make2',\n",
       "                                                                          'make3',\n",
       "                                                                          'make4',\n",
       "                                                                          'make5',\n",
       "                                                                          'make6',\n",
       "                                                                          'make7',\n",
       "                                                                          'make8',\n",
       "                                                                          'make9',\n",
       "                                                                          'make10',\n",
       "                                                                          'make11',\n",
       "                                                                          'make12',\n",
       "                                                                          'make13',\n",
       "                                                                          'make14',\n",
       "                                                                          'make15',\n",
       "                                                                          'make16...\n",
       "                                                                          'Nbr_of_prod_purchas1',\n",
       "                                                                          'Nbr_of_prod_purchas2',\n",
       "                                                                          'Nbr_of_prod_purchas3',\n",
       "                                                                          'Nbr_of_prod_purchas4',\n",
       "                                                                          'Nbr_of_prod_purchas5',\n",
       "                                                                          'Nbr_of_prod_purchas6', ...])])),\n",
       "                                       ('model',\n",
       "                                        RandomForestClassifier(random_state=0,\n",
       "                                                               verbose=True))],\n",
       "                                verbose=True),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [10, 20, 30],\n",
       "                         'model__n_estimators': [400, 500, 700]},\n",
       "             scoring='average_precision', verbose=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 20, 'model__n_estimators': 400}\n",
      "0.18999914433325743\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = load_train_df(X_test_file)\n",
    "X_test_df, _, _ = df_to_input(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {k.replace(\"model__\", \"\"): v for k, v in grid.best_params_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'n_estimators': 400}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", RandomForestClassifier(random_state=0, **best_params)),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23198, 121)\n",
      "(92790, 121)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_df.shape)\n",
    "print(X_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.keyedvectors:loading projection weights from /Users/charles/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "INFO:gensim.utils:KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/charles/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-11-13T22:50:01.476979', 'gensim': '4.3.0', 'python': '3.10.13 (main, Sep 11 2023, 08:24:56) [Clang 14.0.6 ]', 'platform': 'macOS-14.0-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  25.3s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  16.6s\n"
     ]
    }
   ],
   "source": [
    "out = full_pipeline.fit(X_train_df, y_train_df).predict_proba(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m8/1pn02zvd5rn8khdmf1r7t7sc0000gn/T/ipykernel_25684/3316615219.py:2: DtypeWarning: Columns (20,21,22,23,24,68,69,70,71,72,92,93,94,95,96,97,106,107,108,109,110,111,112,113,114,115,116,117,118) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  IDs = pd.read_csv(X_test_file)[\"ID\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>fraud_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23198.000000</td>\n",
       "      <td>23198.000000</td>\n",
       "      <td>23198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11598.500000</td>\n",
       "      <td>58091.621605</td>\n",
       "      <td>0.014031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6696.830108</td>\n",
       "      <td>33465.131873</td>\n",
       "      <td>0.036607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5799.250000</td>\n",
       "      <td>29355.500000</td>\n",
       "      <td>0.000515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11598.500000</td>\n",
       "      <td>58128.000000</td>\n",
       "      <td>0.003159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17397.750000</td>\n",
       "      <td>87016.750000</td>\n",
       "      <td>0.015065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23197.000000</td>\n",
       "      <td>115987.000000</td>\n",
       "      <td>0.968746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index             ID    fraud_flag\n",
       "count  23198.000000   23198.000000  23198.000000\n",
       "mean   11598.500000   58091.621605      0.014031\n",
       "std     6696.830108   33465.131873      0.036607\n",
       "min        0.000000       3.000000      0.000000\n",
       "25%     5799.250000   29355.500000      0.000515\n",
       "50%    11598.500000   58128.000000      0.003159\n",
       "75%    17397.750000   87016.750000      0.015065\n",
       "max    23197.000000  115987.000000      0.968746"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ = out[:, 1]\n",
    "IDs = pd.read_csv(X_test_file)[\"ID\"]\n",
    "df = pd.DataFrame({\"ID\": IDs, \"fraud_flag\": out_})\n",
    "df = df.reset_index()\n",
    "df.to_csv(\"out.csv\", index=False)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fraud_flag\"].hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Challenge0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
